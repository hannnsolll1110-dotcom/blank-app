# app.py
import os, glob, pathlib
import numpy as np
import pandas as pd
import streamlit as st

# ML
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,
    confusion_matrix, RocCurveDisplay
)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier

import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="ì‹ ìš©ì¹´ë“œ ê³ ê° ì´íƒˆ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ’³", layout="wide")
st.title("ğŸ’³ ì‹ ìš©ì¹´ë“œ ê³ ê° ì´íƒˆ(Churn) ëŒ€ì‹œë³´ë“œ")
st.caption("ëª©ì : ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ë° ì·¨ì•½ ì„¸ê·¸ë¨¼íŠ¸(ê³ ë ¹ì¸µÂ·ë””ì§€í„¸ ë¹„í™œì„±) ì§„ë‹¨ â†’ ì„œë¹„ìŠ¤ ê°œì„ /ìœ ì§€ ì „ëµ")

# ----------------------------
# 0) ë°ì´í„° ë¡œë“œ
# ----------------------------
st.sidebar.header("ë°ì´í„°")
mode = st.sidebar.radio("ë°ì´í„° ì†ŒìŠ¤", ["KaggleHub ìë™ ë‹¤ìš´ë¡œë“œ", "CSV ì—…ë¡œë“œ"], horizontal=True)

def load_from_kagglehub():
    """
    ìºê¸€: gonieahn/zero-base-project-creditcard-analysis
    ì•ˆì— í¬í•¨ëœ CSVë¥¼ íƒìƒ‰í•´ì„œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ íŒŒì¼ì„ ì½ëŠ”ë‹¤.
    """
    try:
        import kagglehub
        path = kagglehub.dataset_download("gonieahn/zero-base-project-creditcard-analysis")
        # ëŒ€ê°œ í•œ í´ë” ë‚´ csvê°€ ì—¬ëŸ¬ ê°œ ìˆìŒ â†’ 'churn' ë˜ëŠ” 'attrition' ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        candidates = glob.glob(os.path.join(path, "**", "*.csv"), recursive=True)
        if not candidates:
            return None, "CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # ìš°ì„ ìˆœìœ„: churn/attrition í¬í•¨ â†’ ê·¸ ì™¸ëŠ” ì²« ë²ˆì§¸
        ranked = sorted(
            candidates,
            key=lambda p: (("churn" not in p.lower()) and ("attrition" not in p.lower()), len(p))
        )
        df = pd.read_csv(ranked[0])
        return df, f"Loaded: {pathlib.Path(ranked[0]).name}"
    except Exception as e:
        return None, f"ì˜¤ë¥˜: {e}"

uploaded = None
if mode == "CSV ì—…ë¡œë“œ":
    uploaded = st.sidebar.file_uploader("CSV íŒŒì¼ ì„ íƒ", type=["csv"])
    if uploaded:
        df = pd.read_csv(uploaded)
        source_msg = f"Uploaded: {uploaded.name}"
    else:
        df = None
        source_msg = "CSVë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”."
else:
    df, source_msg = load_from_kagglehub()

st.sidebar.caption(source_msg)

if df is None or df.empty:
    st.warning("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. CSV ì—…ë¡œë“œ ë˜ëŠ” KaggleHub ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    st.stop()

# ì»¬ëŸ¼ëª… ì†Œë¬¸ì í†µì¼
df.columns = [c.strip().lower() for c in df.columns]

# ----------------------------
# 1) ì»¬ëŸ¼ ë§¤í•‘ (ë°ì´í„°ì…‹ ë³€í˜• ëŒ€ì‘)
# ----------------------------
# í”í•œ ì»¬ëŸ¼ í›„ë³´ë“¤(ë‹¤ ìˆì§€ ì•Šì•„ë„ ì‘ë™)
CAND = {
    "target": ["attrition_flag", "churn", "is_churn", "customer_status"],
    "age": ["age", "customer_age"],
    "gender": ["gender", "sex"],
    "marital": ["marital_status", "marital", "maritalstatus"],
    "income_cat": ["income_category", "income_cat", "income_bracket"],
    "card_type": ["card_category", "card_type", "card"],
    "tenure": ["months_on_book", "tenure_months", "tenure"],
    "inactive_m": ["months_inactive_12_mon", "inactive_months", "months_inactive"],
    "contacts_m": ["contacts_count_12_mon", "contacts_12m", "contacts"],
    "credit_limit": ["credit_limit", "clv", "creditlimit"],
    "total_bal": ["total_trans_amt", "total_amt_chng_q4_q1", "total_balance", "total_amt"],
    "total_cnt": ["total_trans_ct", "total_ct_chng_q4_q1", "txn_count", "trans_count"]
}

def pick(colnames):
    for c in colnames:
        if c in df.columns:
            return c
    return None

COL = {k: pick(v) for k, v in CAND.items()}
target_col = COL["target"]

# íƒ€ê¹ƒì´ ì—†ìœ¼ë©´ ì¶”ì • ë¶ˆê°€ â†’ ì¢…ë£Œ
if target_col is None:
    st.error("íƒ€ê¹ƒ(ì´íƒˆ ì—¬ë¶€) ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í›„ë³´: " + ", ".join(CAND["target"]))
    st.stop()

# ì´íƒˆ í”Œë˜ê·¸ í‘œì¤€í™” (1=ì´íƒˆ, 0=ìœ ì§€)
y_raw = df[target_col].astype(str).str.lower()
if set(np.unique(y_raw)) - {"0", "1"}:
    # ë¬¸ìì—´ ë²”ì£¼í˜•ì„ 0/1ë¡œ ë§¤í•‘(ê°€ì¥ í”í•œ ê·œì¹™)
    # 'attrited' / 'churned' / 'yes' â†’ 1, ë‚˜ë¨¸ì§€ â†’ 0
    y = y_raw.isin(["1", "true", "yes", "y", "attrited customer", "churned", "attrited", "exited"]).astype(int)
else:
    y = y_raw.astype(int)

# ì‚¬ìš© í›„ë³´ í”¼ì²˜ ëª©ë¡
feature_candidates = [
    COL["age"], COL["gender"], COL["marital"], COL["income_cat"], COL["card_type"],
    COL["tenure"], COL["inactive_m"], COL["contacts_m"],
    COL["credit_limit"], COL["total_bal"], COL["total_cnt"]
]
features = [c for c in feature_candidates if c is not None and c in df.columns]
X = df[features].copy()

# íƒ€ì… ì¶”ë¡ 
num_cols = [c for c in features if pd.api.types.is_numeric_dtype(X[c])]
cat_cols = [c for c in features if c not in num_cols]

# ----------------------------
# ì‚¬ì´ë“œë°” í•„í„° (ì—°ë ¹/ë¹„í™œì„±/ì¹´í…Œê³ ë¦¬)
# ----------------------------
st.sidebar.header("í•„í„°")
if COL["age"] in X.columns:
    age_min, age_max = int(X[COL["age"]].min()), int(X[COL["age"]].max())
    age_range = st.sidebar.slider("ì—°ë ¹ ë²”ìœ„", min_value=age_min, max_value=age_max,
                                  value=(age_min, age_max))
else:
    age_range = None

inactive_filter = None
if COL["inactive_m"] in X.columns:
    imax = int(X[COL["inactive_m"]].max())
    inactive_filter = st.sidebar.slider("ìµœê·¼ 12ê°œì›” ë¹„í™œì„± ê°œì›” ìˆ˜", 0, imax, (0, imax))

cat_filters = {}
for c in cat_cols:
    opts = sorted(X[c].dropna().astype(str).unique().tolist())
    sel = st.sidebar.multiselect(f"{c} ì„ íƒ", opts)
    if sel:
        cat_filters[c] = sel

# í•„í„° ì ìš©
mask = pd.Series(True, index=X.index)
if age_range and COL["age"] in X.columns:
    mask &= (X[COL["age"]] >= age_range[0]) & (X[COL["age"]] <= age_range[1])
if inactive_filter and COL["inactive_m"] in X.columns:
    mask &= (X[COL["inactive_m"]] >= inactive_filter[0]) & (X[COL["inactive_m"]] <= inactive_filter[1])
for c, vs in cat_filters.items():
    mask &= X[c].astype(str).isin(vs)

Xf, yf = X[mask].copy(), y[mask].copy()

# ----------------------------
# íƒ­ êµ¬ì„±: â‘ ê°œìš” â‘¡ëª¨ë¸ â‘¢ì„¸ê·¸ë¨¼íŠ¸
# ----------------------------
tab1, tab2, tab3 = st.tabs(["â‘  ê°œìš”", "â‘¡ ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸", "â‘¢ ì·¨ì•½ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì‚¬ì´íŠ¸"])

# ----------------------------
# íƒ­ 1) ê°œìš”
# ----------------------------
with tab1:
    st.subheader("ë°ì´í„° ê°œìš”")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("í‘œë³¸ ìˆ˜", f"{len(Xf):,}")
    c2.metric("ì´íƒˆ ë¹„ìœ¨(í•„í„° ì ìš©)", f"{(yf.mean()*100):.1f}%")
    if COL["inactive_m"] in Xf.columns:
        c3.metric("í‰ê·  ë¹„í™œì„± ê°œì›”", f"{Xf[COL['inactive_m']].mean():.2f}")
    if COL["tenure"] in Xf.columns:
        c4.metric("í‰ê·  ê°€ì…ê¸°ê°„(ê°œì›”)", f"{Xf[COL['tenure']].mean():.2f}")

    st.markdown("**ì´íƒˆ/ìœ ì§€ ë¶„í¬**")
    fig = px.histogram(yf.replace({1: "Churned", 0: "Active"}), color= yf.replace({1: "Churned", 0: "Active"}))
    st.plotly_chart(fig, use_container_width=True)

    # ì—°ë ¹/ë¹„í™œì„±/ê±°ë˜ìˆ˜ ë“± ë¶„í¬
    grid_num_cols = [c for c in [COL["age"], COL["inactive_m"], COL["total_cnt"], COL["credit_limit"]] if c in Xf.columns]
    if grid_num_cols:
        st.markdown("**ì£¼ìš” ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„í¬(ì´íƒˆ ì—¬ë¶€ë³„)**")
        for c in grid_num_cols:
            st.plotly_chart(px.box(pd.DataFrame({c: Xf[c], "churn": yf}),
                                   x="churn", y=c, points="all", color="churn"), use_container_width=True)

# ----------------------------
# íƒ­ 2) ì˜ˆì¸¡ ëª¨ë¸
# ----------------------------
with tab2:
    st.subheader("ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸")
    st.caption("ìˆ˜ì¹˜í˜•: í‘œì¤€í™” / ë²”ì£¼í˜•: ì›-í•« ì¸ì½”ë”© â†’ ë¶„ë¥˜ê¸°(ë¡œì§€ìŠ¤í‹± ë˜ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ë¶€ìŠ¤íŒ…)")

    test_size = st.slider("ê²€ì¦ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.4, 0.2, step=0.05)
    rnd = st.number_input("random_state", 1, 9999, 42, step=1)
    model_name = st.selectbox("ëª¨ë¸", ["LogisticRegression", "GradientBoostingClassifier"])

    X_train, X_test, y_train, y_test = train_test_split(Xf, yf, test_size=test_size, random_state=rnd, stratify=yf)

    pre = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), num_cols),
            ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols),
        ],
        remainder="drop"
    )

    if model_name == "LogisticRegression":
        clf = LogisticRegression(max_iter=300, class_weight="balanced")
    else:
        clf = GradientBoostingClassifier()

    pipe = Pipeline([("prep", pre), ("clf", clf)])
    pipe.fit(X_train, y_train)
    pred = pipe.predict(X_test)
    proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe, "predict_proba") else None

    # ì„±ëŠ¥ì§€í‘œ
    colm = st.columns(5)
    colm[0].metric("Accuracy", f"{accuracy_score(y_test, pred):.3f}")
    colm[1].metric("Precision", f"{precision_score(y_test, pred):.3f}")
    colm[2].metric("Recall", f"{recall_score(y_test, pred):.3f}")
    colm[3].metric("F1", f"{f1_score(y_test, pred):.3f}")
    if proba is not None:
        colm[4].metric("ROC-AUC", f"{roc_auc_score(y_test, proba):.3f}")

    # ROC Curve
    if proba is not None:
        fpr, tpr = RocCurveDisplay.from_predictions(y_test, proba).fpr, RocCurveDisplay.from_predictions(y_test, proba).tpr
        roc_fig = go.Figure()
        roc_fig.add_trace(go.Scatter(x=fpr, y=tpr, mode="lines", name="ROC"))
        roc_fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode="lines", name="Baseline", line=dict(dash="dash")))
        roc_fig.update_layout(title="ROC Curve", xaxis_title="FPR", yaxis_title="TPR", height=400)
        st.plotly_chart(roc_fig, use_container_width=True)

    # ì¤‘ìš” ë³€ìˆ˜(ë¡œì§€ìŠ¤í‹±: ì ˆëŒ€ ê³„ìˆ˜ / GBoost: feature_importances_)
    st.markdown("**ë³€ìˆ˜ ì¤‘ìš”ë„(ì°¸ê³ ìš©)**")
    # í”¼ì²˜ëª… ë³µêµ¬
    ohe = pipe.named_steps["prep"].named_transformers_["cat"]
    num_names = num_cols
    cat_names = []
    if len(cat_cols) > 0:
        try:
            cat_names = list(ohe.get_feature_names_out(cat_cols))
        except Exception:
            # êµ¬ë²„ì „ í˜¸í™˜
            cat_names = list(ohe.get_feature_names(cat_cols))
    all_feat_names = num_names + cat_names

    importances = None
    if model_name == "GradientBoostingClassifier" and hasattr(pipe.named_steps["clf"], "feature_importances_"):
        importances = pipe.named_steps["clf"].feature_importances_
    elif model_name == "LogisticRegression" and hasattr(pipe.named_steps["clf"], "coef_"):
        # ê³„ìˆ˜ì˜ ì ˆëŒ€ê°’
        importances = np.abs(pipe.named_steps["clf"].coef_[0])

    if importances is not None and len(all_feat_names) == len(importances):
        imp_df = pd.DataFrame({"feature": all_feat_names, "importance": importances})
        imp_df = imp_df.sort_values("importance", ascending=False).head(20)
        st.plotly_chart(px.bar(imp_df, x="importance", y="feature", orientation="h"), use_container_width=True)
    else:
        st.info("ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤(í”¼ì²˜ëª…/ê³„ìˆ˜ ë¶ˆì¼ì¹˜ ë˜ëŠ” ëª¨ë¸ í•œê³„).")

# ----------------------------
# íƒ­ 3) ì·¨ì•½ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì‚¬ì´íŠ¸
# ----------------------------
with tab3:
    st.subheader("ì·¨ì•½ ì„¸ê·¸ë¨¼íŠ¸ (ê³ ë ¹ì¸µÂ·ë¹„í™œì„±Â·í•œë„Â·ê±°ë˜)")
    # ê³ ë ¹ ê¸°ì¤€(ì¡°ì • ê°€ëŠ¥)
    senior_cut = st.slider("ê³ ë ¹ ê¸°ì¤€ ì—°ë ¹", 55, 80, 60, step=5) if COL["age"] in Xf.columns else None

    vis_cols = []
    if COL["age"] in Xf.columns: vis_cols.append(COL["age"])
    if COL["inactive_m"] in Xf.columns: vis_cols.append(COL["inactive_m"])
    if COL["total_cnt"] in Xf.columns: vis_cols.append(COL["total_cnt"])
    if COL["credit_limit"] in Xf.columns: vis_cols.append(COL["credit_limit"])

    # (A) ì—°ë ¹ëŒ€ë³„ ì´íƒˆë¥ 
    if COL["age"] in Xf.columns:
        bins = [0, 30, 40, 50, 60, 70, 120]
        labels = ["<30", "30s", "40s", "50s", "60s", "70+"]
        age_bin = pd.cut(Xf[COL["age"]], bins=bins, labels=labels, right=False)
        st.markdown("**ì—°ë ¹ëŒ€ë³„ ì´íƒˆë¥ **")
        ag = pd.DataFrame({"age_bin": age_bin, "churn": yf[mask]})
        ag = ag.groupby("age_bin")["churn"].mean().reset_index()
        st.plotly_chart(px.bar(ag, x="age_bin", y="churn", text="churn", range_y=[0, 1]), use_container_width=True)

    # (B) ë¹„í™œì„± ëŒ€ë¹„ ì´íƒˆë¥ 
    if COL["inactive_m"] in Xf.columns:
        st.markdown("**ìµœê·¼ 12ê°œì›” ë¹„í™œì„± ê°œì›” ìˆ˜ vs ì´íƒˆë¥ **")
        im = pd.DataFrame({COL["inactive_m"]: Xf[COL["inactive_m"]], "churn": yf[mask]})
        im[COL["inactive_m"]] = im[COL["inactive_m"]].astype(int)
        gr = im.groupby(COL["inactive_m"])["churn"].mean().reset_index()
        st.plotly_chart(px.line(gr, x=COL["inactive_m"], y="churn", markers=True), use_container_width=True)

    # (C) í•œë„/ê±°ë˜ ìˆ˜ì— ë”°ë¥¸ ìœ„í—˜ë„
    if COL["credit_limit"] in Xf.columns and COL["total_cnt"] in Xf.columns:
        st.markdown("**ì‹ ìš©í•œë„ Ã— ê±°ë˜ê±´ìˆ˜ vs ì´íƒˆ ë¹„ìœ¨**")
        tmp = pd.DataFrame({
            "limit": Xf[COL["credit_limit"]],
            "txcnt": Xf[COL["total_cnt"]],
            "churn": yf[mask]
        }).dropna()
        ql = pd.qcut(tmp["limit"], q=5, duplicates="drop")
        qc = pd.qcut(tmp["txcnt"], q=5, duplicates="drop")
        heat = tmp.groupby([ql, qc])["churn"].mean().reset_index()
        heat["limit_q"] = heat[ql.name].astype(str)
        heat["tx_q"] = heat[qc.name].astype(str)
        fig = px.density_heatmap(heat, x="tx_q", y="limit_q", z="churn",
                                 color_continuous_scale="Reds", histfunc="avg")
        st.plotly_chart(fig, use_container_width=True)

    # (D) ê³ ë ¹ì¸µ ì„¸ë¶€(ì„ íƒ)
    if senior_cut and COL["age"] in Xf.columns:
        st.markdown(f"**ê³ ë ¹ì¸µ(â‰¥{senior_cut}) ì„¸ê·¸ë¨¼íŠ¸ ìš”ì•½**")
        senior_mask = Xf[COL["age"]] >= senior_cut
        s_df = Xf[senior_mask]
        s_y = yf[mask][senior_mask] if hasattr(yf[mask], "__len__") else yf[senior_mask]

        c1, c2, c3 = st.columns(3)
        c1.metric("ê³ ë ¹ì¸µ í‘œë³¸", f"{len(s_df):,}")
        c2.metric("ê³ ë ¹ì¸µ ì´íƒˆë¥ ", f"{(s_y.mean()*100):.1f}%")
        if COL["inactive_m"] in s_df.columns:
            c3.metric("í‰ê·  ë¹„í™œì„± ê°œì›”", f"{s_df[COL['inactive_m']].mean():.2f}")

        # ê³ ë ¹ì¸µ ë‚´ ì£¼ìš” ë¶ˆë¦¬ ìš”ì¸(ë‹¨ë³€ëŸ‰) â€“ ì˜ˆì‹œ: ë¹„í™œì„±/ê±°ë˜ê±´ìˆ˜
        charts = []
        if COL["inactive_m"] in s_df.columns:
            charts.append((COL["inactive_m"], "ë¹„í™œì„± ê°œì›”"))
        if COL["total_cnt"] in s_df.columns:
            charts.append((COL["total_cnt"], "ê±°ë˜ ê±´ìˆ˜"))

        for col, label in charts:
            df_plot = pd.DataFrame({label: s_df[col], "churn": s_y})
            df_plot[label] = pd.qcut(df_plot[label], q=5, duplicates="drop")
            g = df_plot.groupby(label)["churn"].mean().reset_index()
            st.plotly_chart(px.bar(g, x=label, y="churn", text="churn"), use_container_width=True)

st.divider()
st.caption("í•´ì„ ê°€ì´ë“œ: ë¹„í™œì„±ê°œì›”â†‘, ê±°ë˜ê±´ìˆ˜â†“, (í•„ìš” ì‹œ) ê³ ë ¹ì¸µì—ì„œ ì´íƒˆë¥ ì´ ë†’ê²Œ ë‚˜íƒ€ë‚˜ë©´ 'ê°„í¸ ì¸ì¦Â·ë¦¬ë§ˆì¸ë“œÂ·ëŒ€ì²´ì±„ë„' ìš°ì„  ì ìš© íƒ€ê¹ƒ.")
